{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-mnist\n",
      "  Using cached python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: python-mnist\n",
      "Successfully installed python-mnist-0.7\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is System\n",
      " Volume Serial Number is E44B-3C76\n",
      "\n",
      " Directory of C:\\WorkSpace\\Amit\\edvancer\n",
      "\n",
      "07/27/2022  06:58 PM    <DIR>          .\n",
      "07/27/2022  06:58 PM    <DIR>          ..\n",
      "07/27/2022  06:58 PM    <DIR>          .ipynb_checkpoints\n",
      "07/27/2022  06:58 PM            27,709 1.2 CNN with Tensorflow.ipynb\n",
      "07/27/2022  06:52 PM         5,421,523 Convolution Neural Network.pdf\n",
      "07/27/2022  06:54 PM    <DIR>          mnist_data\n",
      "               2 File(s)      5,449,232 bytes\n",
      "               4 Dir(s)  775,117,860,864 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST(r'mnist_data')\n",
    "images_train, labels_train = mndata.load_training()\n",
    "images_test,labels_test=mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train=np.array(labels_train).reshape(-1,1)\n",
    "labels_test=np.array(labels_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot=OneHotEncoder()\n",
    "onehot.fit(labels_train)\n",
    "labels_train=onehot.transform(labels_train)\n",
    "labels_test=onehot.transform(labels_test)\n",
    "labels_train=labels_train.toarray()\n",
    "labels_test=labels_test.toarray()\n",
    "images_train=np.array(images_train).reshape(60000,784)\n",
    "images_test=np.array(images_test).reshape(10000,784)\n",
    "images_train=images_train/255\n",
    "images_test=images_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# x_ph = tf.placeholder(tf.float32, shape=[None, 784]) \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_ph \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m784\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# y_ph = tf.placeholder(tf.float32, shape=[None, 10])\u001b[39;00m\n\u001b[0;32m      4\u001b[0m y_ph \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32, shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m])\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ivyp\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3343\u001b[0m, in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   3296\u001b[0m \u001b[38;5;124;03m\"\"\"Inserts a placeholder for a tensor that will be always fed.\u001b[39;00m\n\u001b[0;32m   3297\u001b[0m \n\u001b[0;32m   3298\u001b[0m \u001b[38;5;124;03m**Important**: This tensor will produce an error if evaluated. Its value must\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3340\u001b[0m \u001b[38;5;124;03m@end_compatibility\u001b[39;00m\n\u001b[0;32m   3341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 3343\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.placeholder() is not compatible with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3344\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen_array_ops\u001b[38;5;241m.\u001b[39mplaceholder(dtype\u001b[38;5;241m=\u001b[39mdtype, shape\u001b[38;5;241m=\u001b[39mshape, name\u001b[38;5;241m=\u001b[39mname)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "# x_ph = tf.placeholder(tf.float32, shape=[None, 784]) \n",
    "x_ph = tf.compat.v1.placeholder(tf.float32, shape=[None, 784]) \n",
    "# y_ph = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y_ph = tf.compat.v1.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally an image is simply a flat array of 784 numbers representing pixels\n",
    "# we are reshaping it to original dimension of 28x28X1 , had this been a colored image. \n",
    "# there will be 3 channels instead of just 1 on the third dimension\n",
    "x_image = tf.reshape(x_ph, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-1028829bc7f6>:3: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 200])\n",
    "b_fc2 = bias_variable([200])\n",
    "\n",
    "h_fc2= tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "h_fc2_drop=tf.nn.dropout(h_fc2,keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc3 = weight_variable([200, 10])\n",
    "b_fc3 = bias_variable([10])\n",
    "\n",
    "y_conv_logits=tf.matmul(h_fc2_drop, W_fc3) + b_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_ph, \n",
    "                                            logits=y_conv_logits))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv_logits, 1),\n",
    "                              tf.argmax(y_ph, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "test_labels_predicted=tf.argmax(y_conv_logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06 & testing accuracy 0.101\n",
      "step 100, training accuracy 0.9 & testing accuracy 0.9252\n",
      "step 200, training accuracy 0.96 & testing accuracy 0.9543\n",
      "step 300, training accuracy 0.98 & testing accuracy 0.9642\n",
      "step 400, training accuracy 0.92 & testing accuracy 0.9695\n",
      "step 500, training accuracy 0.96 & testing accuracy 0.9763\n",
      "step 600, training accuracy 1 & testing accuracy 0.9755\n",
      "step 700, training accuracy 0.98 & testing accuracy 0.9807\n",
      "step 800, training accuracy 0.94 & testing accuracy 0.9773\n",
      "step 900, training accuracy 0.98 & testing accuracy 0.9821\n",
      "test accuracy 0.9791\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(1000):\n",
    "        rand_int=np.random.choice(range(60000),50)\n",
    "        x_train_batch=images_train[rand_int]\n",
    "        y_train_batch=labels_train[rand_int]\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x_ph: x_train_batch, y_ph: y_train_batch, keep_prob: 1.0})\n",
    "            test_accuracy=accuracy.eval(feed_dict={x_ph: images_test, y_ph: labels_test, keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g & testing accuracy %g' % (i, train_accuracy,test_accuracy))\n",
    "            \n",
    "        train_step.run(feed_dict={x_ph: x_train_batch, y_ph: y_train_batch, keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "      x_ph: images_test, y_ph: labels_test, keep_prob: 1.0}))\n",
    "    test_labels_predicted=sess.run(test_labels_predicted,feed_dict={x_ph:images_test,keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>974</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>984</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>979</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>873</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>939</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>952</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0     1    2    3    4    5    6     7    8    9\n",
       "row_0                                                    \n",
       "0      974     1    0    0    0    0    4     1    0    0\n",
       "1        0  1134    1    0    0    0    0     0    0    0\n",
       "2        5    18  984    1    2    0    1    18    3    0\n",
       "3        0     0    4  979    0   11    0    12    3    1\n",
       "4        0     2    0    0  976    0    0     1    1    2\n",
       "5        2     1    0    1    0  873    3     2    9    1\n",
       "6        2     5    0    0    4    1  939     0    7    0\n",
       "7        0     5    3    1    0    0    0  1017    1    1\n",
       "8        6     3    1    1    3    0    1     4  952    3\n",
       "9        1     7    0    1   15    3    0    14    5  963"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(np.argmax(labels_test,axis=1),test_labels_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.argmax(labels_test,axis=1)!=test_labels_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18,\n",
       " 92,\n",
       " 266,\n",
       " 320,\n",
       " 321,\n",
       " 326,\n",
       " 359,\n",
       " 381,\n",
       " 449,\n",
       " 492,\n",
       " 495,\n",
       " 511,\n",
       " 582,\n",
       " 583,\n",
       " 593,\n",
       " 646,\n",
       " 659,\n",
       " 684,\n",
       " 717,\n",
       " 740,\n",
       " 797,\n",
       " 882,\n",
       " 883,\n",
       " 924,\n",
       " 938,\n",
       " 947,\n",
       " 965,\n",
       " 1014,\n",
       " 1032,\n",
       " 1033,\n",
       " 1062,\n",
       " 1138,\n",
       " 1181,\n",
       " 1182,\n",
       " 1204,\n",
       " 1226,\n",
       " 1232,\n",
       " 1247,\n",
       " 1260,\n",
       " 1299,\n",
       " 1326,\n",
       " 1337,\n",
       " 1402,\n",
       " 1425,\n",
       " 1429,\n",
       " 1500,\n",
       " 1530,\n",
       " 1621,\n",
       " 1678,\n",
       " 1681,\n",
       " 1709,\n",
       " 1717,\n",
       " 1722,\n",
       " 1790,\n",
       " 1878,\n",
       " 1901,\n",
       " 1965,\n",
       " 2043,\n",
       " 2044,\n",
       " 2098,\n",
       " 2109,\n",
       " 2129,\n",
       " 2135,\n",
       " 2186,\n",
       " 2189,\n",
       " 2237,\n",
       " 2293,\n",
       " 2298,\n",
       " 2299,\n",
       " 2387,\n",
       " 2406,\n",
       " 2414,\n",
       " 2422,\n",
       " 2433,\n",
       " 2447,\n",
       " 2454,\n",
       " 2462,\n",
       " 2488,\n",
       " 2534,\n",
       " 2582,\n",
       " 2597,\n",
       " 2598,\n",
       " 2654,\n",
       " 2720,\n",
       " 2743,\n",
       " 2760,\n",
       " 2863,\n",
       " 2896,\n",
       " 2921,\n",
       " 2927,\n",
       " 2945,\n",
       " 2953,\n",
       " 2979,\n",
       " 2995,\n",
       " 3005,\n",
       " 3030,\n",
       " 3060,\n",
       " 3073,\n",
       " 3207,\n",
       " 3250,\n",
       " 3336,\n",
       " 3369,\n",
       " 3474,\n",
       " 3475,\n",
       " 3503,\n",
       " 3511,\n",
       " 3520,\n",
       " 3558,\n",
       " 3597,\n",
       " 3599,\n",
       " 3688,\n",
       " 3785,\n",
       " 3796,\n",
       " 3808,\n",
       " 3850,\n",
       " 3853,\n",
       " 3869,\n",
       " 3985,\n",
       " 4007,\n",
       " 4044,\n",
       " 4075,\n",
       " 4152,\n",
       " 4163,\n",
       " 4176,\n",
       " 4205,\n",
       " 4224,\n",
       " 4248,\n",
       " 4256,\n",
       " 4284,\n",
       " 4289,\n",
       " 4306,\n",
       " 4356,\n",
       " 4369,\n",
       " 4384,\n",
       " 4435,\n",
       " 4472,\n",
       " 4497,\n",
       " 4500,\n",
       " 4536,\n",
       " 4571,\n",
       " 4601,\n",
       " 4615,\n",
       " 4699,\n",
       " 4731,\n",
       " 4740,\n",
       " 4761,\n",
       " 4807,\n",
       " 4808,\n",
       " 4823,\n",
       " 4886,\n",
       " 4956,\n",
       " 4978,\n",
       " 5067,\n",
       " 5127,\n",
       " 5734,\n",
       " 5841,\n",
       " 5842,\n",
       " 5921,\n",
       " 5955,\n",
       " 5973,\n",
       " 5997,\n",
       " 6011,\n",
       " 6035,\n",
       " 6091,\n",
       " 6157,\n",
       " 6166,\n",
       " 6505,\n",
       " 6555,\n",
       " 6569,\n",
       " 6571,\n",
       " 6576,\n",
       " 6597,\n",
       " 6651,\n",
       " 6796,\n",
       " 6847,\n",
       " 6926,\n",
       " 7121,\n",
       " 7233,\n",
       " 7492,\n",
       " 7732,\n",
       " 7842,\n",
       " 8059,\n",
       " 8062,\n",
       " 8069,\n",
       " 8091,\n",
       " 8094,\n",
       " 8095,\n",
       " 8325,\n",
       " 8332,\n",
       " 9009,\n",
       " 9015,\n",
       " 9620,\n",
       " 9634,\n",
       " 9638,\n",
       " 9642,\n",
       " 9655,\n",
       " 9664,\n",
       " 9692,\n",
       " 9729,\n",
       " 9744,\n",
       " 9768,\n",
       " 9770,\n",
       " 9779,\n",
       " 9839,\n",
       " 9883,\n",
       " 9888,\n",
       " 9904,\n",
       " 9905,\n",
       " 9982]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i,x in enumerate(t) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label: 9\n",
      "real label: 8\n"
     ]
    }
   ],
   "source": [
    "ind=947\n",
    "sample_image = images_test[ind] \n",
    "sample_image = np.array(sample_image, dtype='float')\n",
    "pixels = sample_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "print('predicted label:',test_labels_predicted[ind])\n",
    "print('real label:',np.argmax(labels_test[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
